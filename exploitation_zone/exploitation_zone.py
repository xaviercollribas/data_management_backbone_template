import psycopg2
import pandas as pd
from sqlalchemy import create_engine
import sqlalchemy
from airflow.models import Variable

# Define the source and destination database connections
# Define the source and destination database connections
source_conn_params = {
    "dbname": Variable.get("tz_dbname"),
    "user": Variable.get("dbuser"),
    "password": Variable.get("trusted_zone_secret"),
    "host": Variable.get("dbhost"),
}


# Connect to the source and destination databases
try:
    source_conn = psycopg2.connect(**source_conn_params)
    engine = create_engine(f'postgresql://{Variable.get("dbuser")}:{Variable.get("trusted_zone_secret")}@{Variable.get("dbhost")}:5432/{Variable.get("ez_dbname")}')
except psycopg2.Error as e:
    print(f"Error connecting to the databases: {e}")
    exit(1)

# Retrieve a list of all tables in the source database
query = "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'"
tables = pd.read_sql_query(query, source_conn)

# Loop through the tables and copy them to the destination database with 'raw' schema
for table_name in tables['table_name']:
    # Read data from the source table into a DataFrame
    query = f"SELECT * FROM \"{table_name}\""
    df = pd.read_sql_query(query, source_conn)
    if not engine.dialect.has_schema(engine, 'raw'):
        engine.execute(sqlalchemy.schema.CreateSchema('raw'))
    # Specify the destination schema as 'raw' and table name in the destination database
    dest_table_name = table_name

    # Write the DataFrame to the destination table
    df.to_sql(dest_table_name, engine, if_exists='replace', index=False, schema='raw')

    print(f"Table {table_name} copied to {dest_table_name} successfully.")

# Close the database connections
source_conn.close()
